{"kernelspec":{"display_name":"SageMath 6.10","language":"","name":"sagemath"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.10"}}
{"cell_type":"markdown","metadata":{},"source":"$\\newcommand{\\R}{\\mathbb{R}}$\n$\\newcommand{\\transp}{\\mathrm{T}}$"}
{"cell_type":"markdown","metadata":{},"source":"# 1. Context \n\nOur ultimate motivation is to design and improve reachability analysis methodologies for single and hybrid non-linear control systems. Here we will restrict to those single systems which can be written as\n$$\n\\dot{x} = f(x,t) + g(x,t)u + h(x,t)w,\n$$\nwhere $x$ is the *state*, and $f, g, h$ are vector fields of the appropriate dimensions, $u$ is controlled input, and $w$ is an uncontrolled input (e.g. noise). They are often assumed sufficiently regular (Lipshitz continuous), to ensure existence and uniqueness of solutions. The reachability problem is associated to finding the sets in state-space in which the system occupies, often upon restrictions on the initial set (hence we are interested in the *forward-reachable set*), or the final or target set (hence we want to compute the *backward-reachable set*). Moreover, both finite and infinite time horizons are interesting. Hereafter we focus on the FRS for finite time horizon.\n\nThe problem of reachability is closely related to generating approximations of ODE solutions. We can highlight:\n1. In *numerical integration*, one solves iteratively the ODE, with a step-size that can be used to control the local approximation error. This method does not provide guaranteed integration, hence it is not suitable for the purpose of verification.\n2. In *validated integration*, there are two main approaches: (i) in the *discrete*, one discretizes time and approximates the reach pipe sequentially, and the over-approximation is guaranteed by an appropriate bloating factor; (ii) in the *continuous* case, one comes up with another differential equation, whose solution is known to provide an appropriate enclosure of the solution of the objective system.\n\n**Remark**. By no means we attempt to address the relevant literature on validated integration techniques. The literature is vast and vibrant, and the interested reader is suggested to look at numerous recent thesis on this subject (e.g. from the 2000s onwards)."}
{"cell_type":"markdown","metadata":{},"source":"# 2. Preliminaries\n\nThe following concepts will be used throughout the tutorial. In all these definitions we are implicitly in the familiar Euclidean space $\\R^n$, though all of them make sense in one way or another in an abstract metric space."}
{"cell_type":"markdown","metadata":{},"source":"## 2.1. Convex sets\n\nA [convex set](https://en.wikipedia.org/wiki/Convex_set) is a region such that, for every pair of points within the region, every point on the straight line segment that joins the pair of points is also within the region. "}
{"cell_type":"markdown","metadata":{},"source":"## 2.2. Convex hull\n\nThe [convex hull](https://en.wikipedia.org/wiki/Convex_hull) of a set $X \\subseteq \\R^n$ is the smallest convex sets that contains $X$.\n\n*Exercise*. Have a look at the docs for [convex hull](http://doc.sagemath.org/html/en/reference/geometry/sage/geometry/polyhedron/base.html?highlight=convex_hull#sage.geometry.polyhedron.base.Polyhedron_base.convex_hull). Try the example. We will make heavy use of the Polyhedron class in this tutorial."}
{"cell_type":"markdown","metadata":{},"source":"## 2.3. Hausdorff distance and norms \n\nRecall that the $p$-norm of $x \\in \\R^n$ ($1\\leq p <\\infty$) is $||x||_p = \\left( \\sum_i |x_i|^p \\right)^{1/p}$; the supremum norm ($p=\\infty$) is $||x||_\\infty = \\max_i |x_i|$. The reason of the constraint $p \\geq 1$ is due to the fact that we loose convexity if we allow $p<1$. In most applications, convexity is a desired property. This is illustrated in the figures below:\n![alt text](http://upload.wikimedia.org/wikipedia/commons/e/e6/Minkowski3.png \"p-norm\")\n\nThe [Hausdorff distance](https://en.wikipedia.org/wiki/Hausdorff_distance) is a concept that generalizes the notion of distance between points, to distance between *sets of points*. To understand why we need a generalization, think of the following: what would be a reasonable distance between the yellow semidisk and the orange line? between the blue line and the semidisk? between both lines?"}
{"cell_type":"code","execution_count":1,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::342ba7be-78e1-45be-a90c-7913e44535ce","text/plain":"Graphics object consisting of 3 graphics primitives"},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":"disk((0.0,0.0), 1, (pi/4,3*pi/4) ,rgbcolor=(1,1,0)) + line([[0.2,0.5], [1.5,0.5]]) + line([[-0.6,1.1], [0.6,1.1]],color='orange')"}
{"cell_type":"markdown","metadata":{},"source":"More precisely, in the Euclidean space $(\\R^n,||\\cdot||_p)$ the Hausdorff distance between the sets $X$ and $Y$ is defined as\n$$\nd^H_p(X,Y) = \\max \\left\\{ \\sup_{x \\in X} \\inf_{y \\in Y} ||x-y||_p , \\sup_{y \\in Y} \\inf_{x \\in X} ||x-y||_p \\right\\}.\n$$\nIt is worth doing some examples by hand to convince you that this formulation makes sense.\n\n*Exercise*. Answer the questions in relation to the previous plot using the definition of Hausdorff distance, with $p=2$ (usual Euclidean norm). How does the result change with different values of $p$?"}
{"cell_type":"markdown","metadata":{"collapsed":false},"source":"## 2.3. Support function\n\nLet $\\Omega \\subset \\mathbb{R}^n$ be a compact convex set. The support function of $\\Omega$, $\\rho_\\Omega : \\mathbb{R}^n \\to \\mathbb{R}$, is defined as \n\\begin{equation}\n\\rho_\\Omega(d) = \\max_{x \\in \\Omega}~~ d^\\mathrm{T}\\cdot x\n\\end{equation}\nA polyhedral over-approximation of $\\Omega$ can be built via support functions.\n\n**Proposition**. Let $\\{\\ell_1,\\ldots,\\ell_r\\}$ be a family of chosen vectors in $\\R^n$. Let define the half-spaces $H_k = \\{ x \\in \\R^n: \\ell_k^\\transp \\cdot x \\leq \\rho_\\Omega(\\ell_k)\\}$ for all $k=1,\\ldots,r$. Then:\n1. The polyhedron $\\bar{\\Omega} := \\bigcap\\limits_{k = 1}^r H_k$ is an over-approximation of $\\Omega$, that is, $\\Omega \\subseteq \\bar{\\Omega}$.\n2. The over-approximation is *tight*, in the sense that $\\Omega$ touches the faces of $\\bar{\\Omega}$.\n"}
{"cell_type":"markdown","metadata":{},"source":"### 2.3.1. Support function of a convex polytope\n\nIf $\\Omega$ is a convex polytope, $\\Omega = \\{ x \\in \\mathbb{R}^n:~Ax \\leq b\\}$, then its support function is equivalent to solving the [linear program](https://en.wikipedia.org/wiki/Linear_programming) (LP):\n\\begin{equation}\n\\rho_\\Omega(d) = \\text{max} \\{ d^\\mathrm{T}\\cdot x :~ Ax \\leq b \\}\n\\end{equation}\nBelow we implement this function. The class Polyhedron saves the inequalities as [b,A], with the convention that $Ax+b\\geq 0$, so we have to be careful if we use the convention $Ax \\leq b$."}
{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"#Compute support function of a convex polytope (given as (A,b), assuming: Ax <= b)\ndef supp_fun_polyhedron(d, P, showOutput=1): \n    \n    s_LP = MixedIntegerLinearProgram(maximization=True, solver = \"GLPK\")\n    x = s_LP.new_variable(integer=False, nonnegative=False)\n\n    # objective function\n    obj = sum(d[i]*x[i] for i in range(len(d)))\n    s_LP.set_objective(obj)\n    \n    # extract the constraints from P\n    m = len(P.Hrepresentation())\n    n = len(vector( P.Hrepresentation()[0] ))-1\n    b = vector(RR, m)\n    A = matrix(RR, m, n)\n    P_gen = P.Hrep_generator();\n    i=0\n    for pigen in P_gen:\n        pi_vec = pigen.vector()\n        A.set_row(i, -pi_vec[1:len(pi_vec)])\n        b[i] = pi_vec[0]\n        i+=1;\n        \n    s_LP.add_constraint(A * x <= b);    \n        \n    if (showOutput):\n        print '**** Solve LP (using GLPK) ****'    \n        s_LP.show()\n    \n    oval = s_LP.solve()\n    xopt = s_LP.get_values(x);\n    \n    if (showOutput):\n        print 'Objective Value:', oval\n        for i, v in xopt.iteritems():\n            print 'x_%s = %f' % (i, v)\n        print '\\n'\n    return oval, xopt"}
{"cell_type":"markdown","metadata":{},"source":"Let us compute the support function of the unit box at the $x=y$ direction:"}
{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"name":"stdout","output_type":"stream","text":"**** Solve LP (using GLPK) ****\nMaximization:\n  x_0 + x_1\nConstraints:\n  - x_1 <= 1.0\n  - x_0 <= 1.0\n  x_1 <= 1.0\n  x_0 <= 1.0\nVariables:\n  x_0 is a continuous variable (min=-oo, max=+oo)\n  x_1 is a continuous variable (min=-oo, max=+oo)\nObjective Value: 2.0\nx_0 = 1.000000\nx_1 = 1.000000\n\n\n"},{"data":{"text/plain":"(2.0, {0: 1.0, 1: 1.0})"},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":"P = Polyhedron(vertices=[[1,1],[-1,1],[-1,-1],[1,-1]],base_ring=RDF)\nd = [1,1]\nsupp_fun_polyhedron(d, P, showOutput=1)"}
{"cell_type":"markdown","metadata":{},"source":"### 2.3.2. Support function of an ellipse \n\n*Exercise*. What is the support function of an ellipsoid centered at the origin? \n\n*Answer*. Let $E = \\{ x \\in \\R^n : x^\\transp Q x \\leq 1\\}$, where $Q$ is a positive definite symmetric matrix. Then, $\\rho_E(d) = \\sqrt{d^\\transp Q^{-1} d}$."}
{"cell_type":"code","execution_count":3,"metadata":{"collapsed":true,"trusted":false},"outputs":[],"source":"#Compute support function at d of an ellipse input as x^tr*Q*x <= 1\ndef supp_fun_ellipse(d, Q, showOutput=1): \n    if (Q.is_singular()):\n        print 'error: input matrix is not invertible'\n        return\n    return sqrt(d.inner_product((~Q)*d))\n    "}
{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::34d15f64-0638-4ea9-a554-aa08825b4b75","text/plain":"Graphics object consisting of 1 graphics primitive"},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":"# build an ellipse centred at 0, with semiaxes 3 and 1, and tilted 30 deg counterclockwise\nE = ellipse((0,0),3,1,pi/6,fill=True,edgecolor='black',facecolor='red',rgbcolor='green',alpha=0.3)\nE"}
{"cell_type":"markdown","metadata":{},"source":"As shown in the previous cell, sagemath provides a command to plot an ellipse given the semiaxes and at a given angle wrt the coordinates axes. However I didn't find how to extract the $Q$ in one stroke (though this can be easily achieved [through a change of variables](http://www.maa.org/external_archive/joma/Volume8/Kalman/General.html)). Let us instead build the ellipse ourselves. In the way we will encounter the *implicit plot* feature."}
{"cell_type":"code","execution_count":7,"metadata":{"collapsed":false,"trusted":false},"outputs":[{"data":{"image/png":"smc-blob::1c8aa046-e2d8-4d63-9b31-2a3bc4a7431a","text/plain":"Graphics object consisting of 12 graphics primitives"},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":"# Generate a random ellipsoid and plot using implicit plot\nimport random\n\n# define an ellipse as: x^tr*Q*x <= 1\nM = random_matrix(RR, 2, distribution=\"uniform\")\nQ = M.T*M\nf = lambda x, y : Q[0,0]*x^2 + Q[1,1]*y^2 + (Q[0,1]+Q[1,0])*x*y-1\nE = implicit_plot(f,(-5,5),(-3,3),fill=True,alpha=0.5,plot_points=600)\n\n# Try out the overapproximation of an ellipse using support functions\nimport numpy as np\nload(\"../Library/polyFunctions.sage\")\n\n# generate at random k directions, and compute the overapproximation of E using support functions\n# works 'in average': we might get unbounded domains in some cases / 'frozen set'\nk=10\nA = matrix(RR,k,2); b = vector(RR,k)\nfor i in range(k):\n    theta = random.uniform(0, 2*pi.n(digits=5))\n    d = vector(RR,[cos(theta), sin(theta)])\n    s_fun = supp_fun_ellipse(d, Q, showOutput=0)\n    A.set_row(i,d); b[i] = s_fun\n\nOmegaApprox = polytopeFromHrep(A, b)\nE + OmegaApprox.plot(fill=False, color='red')"}